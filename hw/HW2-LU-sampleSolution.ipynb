{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <p style=\"text-align: right;\"> &#9989; Put your name here</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to successfully complete this assignment, you must follow all instructions in this notebook and upload your edited ipynb file with your answers on or before **11:59pm on Friday Feb. 8th**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please read though the entire project before starting!**\n",
    "\n",
    "This homework uses \"the language of linear algebra\" to describe how to solve a common engineering problem efficiently. \n",
    "You may not be familiar with some of the terms. \n",
    "Try to see if you can figure them out in context or use your favorite search engine. \n",
    "If you still don't understand, stop by office hours.\n",
    "\n",
    "\n",
    "# Homework 2: Gaussian Elimination, LU Decomposition, and PDEs\n",
    "\n",
    "\n",
    "<img src=\"https://exclaim.ca/images/Marc_Maron_Thinky_Pain.jpg\">\n",
    "\n",
    "In this homework, you will create algorithms that factorize invertible matrices (i.e., square matrices with linearly independent columns), $A$, into the following decompositions (**note**: the terms *decomposition* and *factorization* are used interchangeably in literature):\n",
    "\n",
    "- LU Decomposition: $A = LU$\n",
    "- Cholesky Decomposition: $A = R^TR\\quad (= LDL^T)$\n",
    "    - This factorization of $A$ into $R^TR$ also requires that $A$ be *symmetric* and *positive-definite*. The latter term simply requires that $x^{T}Ax > 0$ for every nonzero $x \\in \\mathbb{R}^n$. If it is not obvious, you should confirm that $x^{T}Ax$ is always some scalar value (e.g., note that $x^TA = y^T$ for some vector $y\\in\\mathbb{R}^n$, and $y^Tx$ is the dot product between $x$ and $y$ and, hence, a real scalar).\n",
    "    \n",
    "Each matrix in these decompositions is the *matrix product* of <a href=\"https://en.wikipedia.org/wiki/Elementary_matrix\">elementary matrices</a>. \n",
    "Recall that *an elementary matrix differs from the identity matrix (the square matrix with $1$s on the diagonal and $0$s elsewhere) by an elementary row operation*.\n",
    " \n",
    "The use of these matrix decompositions in Numerical Linear Algebra is motivated by computational efficiency or reduction of *computational complexity* (recall \"**Big-O notation**\" and **counting the loops in your matrix multiplication algorithm**) and *numerical stability*. \n",
    "Solving our old friend $Ax = b$ by computing the inverse of $A$, denoted $A^{-1}$, and taking the matrix-vector product $A^{-1}b = x$ is computational resource intensive and numerically unstable, in general. \n",
    "If the $LU$ decomposition of $A$ exists, then it will be less costly and more stable to:\n",
    "1. Solve $Ly = b$ for $y$ by *forward-substitution*; and then\n",
    "2. Solve $Ux = y$ for $x$ by *backward-substitution*\n",
    "\n",
    "A final note to relate Homework 2 to Homework 1: The algorithms presented here are of a different class than those presented in the first homework. \n",
    "The **Jacobi Algorithm** and **Gauss-Siedel Algorithm** are *iterative algorithms*. \n",
    "As you now know, this means that the algorithmic procedure is applied once, twice, and so on, *ad infinitum*, until the output is within a desired tolerance, or until the process has been executed a given number of times (e.g., 1000 iterations). \n",
    "To contrast, the algorithms in this homework are executed in *finite time*. \n",
    "You have already written such an algorithm: **Matrix Multiply** and **Gauss-Jordan Elimination**. \n",
    "It may be useful to bear this distinction in mind as you encounter new algorithms.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# Part 0: Motivations\n",
    "\n",
    "Imagine we have a metal rod that is 1 meter in length and 1 centimeter in diameter. \n",
    "Suppose that we keep each end cooled to $0^{\\circ}$ Celsius and heat the middle to $100^{\\circ}$ Celsius. \n",
    "Then, we let the rod cool and record the temperature distribution across its length.\n",
    "\n",
    "<img src=\"https://tgneast.blob.core.windows.net/content/wp-content/uploads/2014/11/sh74.jpg\" width='300'>\n",
    "\n",
    "We will model this phenomenon using the 1-Dimensional Heat Equation, a Partial Differential Equation (PDE) which relates the first derivative in time of a function, $u(x,t)$, to its second derivative in space. This is formally stated as:\n",
    "\n",
    "$$\\frac{\\partial u(x,t)}{\\partial t} = \\frac{\\partial^{2} u(x,t)}{\\partial x^{2}}.$$\n",
    "\n",
    "In order for our problem to be well-posed, we will use the following boundary and initial conditions:\n",
    "\n",
    "$$u(0,t) = u(1,t) = 0, x \\in [0,1] $$\n",
    "$$u(x,0) = 100\\sin(\\pi x) $$ \n",
    "\n",
    "While not obvious from the equation above, when this PDE is solved numerically (e.g., by a computer), the problem reduces to one of Linear Algebra, namely $Ax=b$. \n",
    "To solve this equation, we need to invert the matrix $A$ or find a clever way to circumvent doing so. \n",
    "Let's attempt the latter.\n",
    "\n",
    "**Note**: This assignment covers a diverse range of concepts. \n",
    "You are only responsible for Linear Algebra content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# Part 1: Gaussian Elimination & LU Decomposition\n",
    "\n",
    "Recall that Gaussian Elimination converts an arbitrary matrix, $A$, into its *row echelon form*. \n",
    "For our purposes, let's suppose that $A$ is a square $n\\times n$ matrix. \n",
    "To simplify our tasks, let us further impose the condition that $A$ is invertible. \n",
    "Thus, the columns of $A$ are linearly independent. \n",
    "This means that Gaussian Elimination will yield an ***upper-triangular*** *matrix*. \n",
    "Let us denote this matrix $U$ for ***upper-triangular***.\n",
    "\n",
    "If there were a function, $f$ that could take $A$ and output $U$, we could think of Gaussian Elimination as the following process:\n",
    "\n",
    "$$f(A)=U$$\n",
    "\n",
    "In fact, we have such a function, or linear map, $L^{-1}$. \n",
    "$L^{-1}$ is a ***unit lower-triangular*** *matrix*. \n",
    "This means that $L^{-1}$ has $1$s on its diagonal and $0$s above. \n",
    "Elements below the diagonal are real numbers.\n",
    "\n",
    "$$L^{-1} = \n",
    "\\left(\n",
    "    \\begin{array}{*5{c}}\n",
    "         1 &  0 &  0 &  0 &  0 \\\\\n",
    "         -l_{21} &  1 &  0 &  0 &  0 \\\\\n",
    "         -l_{31} &  -l_{32} &  1 &  0 &  0 \\\\\n",
    "         -l_{41} &  -l_{42} &  -l_{43} &  1 &  0 \\\\\n",
    "         -l_{51} &  -l_{52} &  -l_{53} &  -l_{54} &  1 \\\\\n",
    "      \\end{array}\n",
    "  \\right)\n",
    "$$\n",
    "\n",
    "(Fret not, dear reader: The use of $-l_{ij}$ instead of $l_{ij}$ for the elements of $L^{-1}$ will become clear in a moment. However, note that for any unit lower-triangular matrix, its subdiagonal entries, $l_{ij}, i>j$, may take any value, so, without loss of generality, we may choose $-l_{ij}$ for its entries.)\n",
    "\n",
    "With this information, we may now rewrite our equation from above as:\n",
    "\n",
    "$$L^{-1}A = U$$\n",
    "\n",
    "You may have noticed the superscript in $L^{-1}$. \n",
    "This just says that $L^{-1}$ is the inverse of some matrix $L$. \n",
    "And for any invertible matrix, $L$, we have that the matrix products:\n",
    "\n",
    "$$L^{-1}L = LL^{-1} = I$$\n",
    "\n",
    "This is analogous to (for every real number $a\\neq 0$): \n",
    "\n",
    "$$a^{-1}\\times a = a\\times a^{-1} = 1$$\n",
    "\n",
    "To understand $L^{-1}$ more deeply, let's turn our attention back to Gaussian Elimination for a moment. For a \"sufficiently nice\" $n\\times n$ matrix $A$, the matrix $L^{-1}$ that takes $A$ to its ***upper-triangular*** or ***row echelon form***, $U$, has the structure:\n",
    "\n",
    "$$L^{-1} = L_{n-1}L_{n-2}...L_{2}L_{1}$$\n",
    "\n",
    "Each of the $L_{i}$s above is an elementary matrix that zeros out the subdiagonal entries of the $i^{th}$ column of $A$. This is **the $i^{th}$ step of** ***Gaussian Elimination*** **applied to** ***the entire $i^{th}$ column of A below the $i^{th}$ diagonal element***.  \n",
    "\n",
    "Let's show this by computation of $L_i$ for a \"nice\" matrix $A$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import all necessary packages\n",
    "%matplotlib inline\n",
    "import scipy.sparse as sparse #this helps to speed up the algorithms, but you will not use it. \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sympy as sym\n",
    "sym.init_printing(use_unicode=True)\n",
    "\n",
    "## These will allow us to see a cool simulation of the Heat Equation problem (if we compute our answers correctly!)\n",
    "from matplotlib import animation, rc\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "L = np.matrix([[1 , 0, 0], [-2, 1,0], [4,2,1]])\n",
    "sym.Matrix(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sym.Matrix(np.linalg.inv(L))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Elimination by Elementary Matrices, $L_i$\n",
    "\n",
    "Let $A$ be the following matrix:\n",
    "\n",
    "$$A = \n",
    "\\begin{bmatrix}\n",
    "    2 &  1 &  1 &  0 \\\\\n",
    "    4 &  3 &  2 &  1 \\\\\n",
    "    8 &  7 &  8 &  5 \\\\\n",
    "    6 &  7 &  9 &  8 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "&#9989; <font color=red>**DO THIS:**</font> Create a $4 \\times 4$ **unit lower-triangular** matrix, $L_1$ that eliminates all of the subdiagonal entries of $A$ in the first column. Display the matrix $L_1$ using SymPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.matrix([[2,1,1,0],[4,3,2,1],[8,7,8,5],[6,7,8,8]]) # Here is A for your convenience\n",
    "As = sym.Matrix(A)\n",
    "As"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Type your answer here ##\n",
    "L1 = np.matrix([[1,,,],[,1,,],[,,1,],[,,,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ANSWER ##\n",
    "L1 = np.matrix([[1,0,0,0],[-2,1,0,0],[-4,0,1,0],[-3,0,0,1]])\n",
    "L1s = sym.Matrix(L1)\n",
    "L1s\n",
    "## ANSWER ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L1*A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We should now have the following:\n",
    "\n",
    "$$L_{1}A = A^{(1)} =\n",
    "\\begin{bmatrix}\n",
    "    2 &  1 &  1 &  0 \\\\\n",
    "    0 &  u_{22} &  u_{23} &  u_{24} \\\\\n",
    "    0 &  x &  x &  x \\\\\n",
    "    0 &  x &  x &  x \\\\\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "    u_{11} &  u_{12} &  u_{13} &  u_{14} \\\\\n",
    "    0 &  u_{22} &  u_{23} &  u_{24} \\\\\n",
    "    0 &  x &  x &  x \\\\\n",
    "    0 &  x &  x &  x \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Since our first row remained unchanged, we know that our $u_{1i}$ (the first row entries of $U$) are now determined. Similarly, we have that the $u_{2i}$ (the second row entries of $U$) are determined as well. The $x$ elements are elements that have changed, but are not yet in their final form.  **Note**: Your $u_{ij}$ will be whole, or Integer ($\\mathbb{Z}$), numbers. \n",
    "\n",
    "&#9989; <font color=red>**DO THIS:**</font> Left-multiply $A$ by $L_1$ to confirm that all of the subdiagonal entries of the first column of $A^{(1)}$ are zero. Display the result via SymPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Type your answer here ##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ANSWER ##\n",
    "A1 = L1*A\n",
    "A1s = sym.Matrix(A1)\n",
    "A1s\n",
    "## ANSWER ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our next step will be to eliminate all nonzero entries from the second column of $A^{(1)} = L_{1}A$ by left multiplication of $L_{2}$. This should yield: \n",
    "\n",
    "$$\\begin{align}A^{(2)} &= L_{2}A^{(1)} \\\\\n",
    "&= L_{2}L_{1}A \\\\\n",
    "&=\n",
    "\\begin{bmatrix}\n",
    "    u_{11} &  u_{12} &  u_{13} &  u_{14} \\\\\n",
    "    0 &  u_{22} &  u_{23} &  u_{24} \\\\\n",
    "    0 &  0 &  u_{33} &  u_{34} \\\\\n",
    "    0 &  0 &  x &  x \\\\\n",
    "\\end{bmatrix}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "&#9989; <font color=red>**DO THIS:**</font> Create a $4 \\times 4$ **unit lower-triangular** matrix, $L_2$ that eliminates all of the subdiagonal entries of the second column of $A^{(1)}$ yielding $A^{(2)}$ as above. Display the matrix $L_2$ using SymPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Type your answer here ##\n",
    "L2 = np.matrix([[1,,,],[,1,,],[,,1,],[,,,1]]) # for your convenience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ANSWER ##\n",
    "L2 = np.matrix([[1,0,0,0],[0,1,0,0],[0,-3,1,0],[0,-4,0,1]])\n",
    "L2s = sym.Matrix(L2)\n",
    "L2s\n",
    "## ANSWER ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; <font color=red>**DO THIS:**</font> Left-multiply $A^{(1)}$ by $L_2$ to confirm that all of the subdiagonal entries of column 2 of $A^{(2)}$ are zero. Display the result via SymPy. **Note**: Your $u_{ij}$ will be whole, or Integer ($\\mathbb{Z}$), numbers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Type your answer here ##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ANSWER ##\n",
    "A2 = L2*A1\n",
    "A2s = sym.Matrix(A2)\n",
    "A2s\n",
    "# sym.latex(A2s)\n",
    "## ANSWER ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should now have:\n",
    "\n",
    "$$\n",
    "\\begin{align}A^{(2)} &= L_{2}A^{(1)} \\\\\n",
    "&= L_{2}L_{1}A \\\\\n",
    "&=\n",
    "\\begin{bmatrix}\n",
    "    u_{11} &  u_{12} &  u_{13} &  u_{14} \\\\\n",
    "    0 &  u_{22} &  u_{23} &  u_{24} \\\\\n",
    "    0 &  0 &  u_{33} &  u_{34} \\\\\n",
    "    0 &  0 &  x &  x \\\\\n",
    "\\end{bmatrix}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "We now want to build the final matrix $L_{3}$ that will take our matrix $A^{(2)}$ to ***upper-triangular*** **form**. So, let's do that!\n",
    "\n",
    "&#9989; <font color=red>**DO THIS:**</font> Create a $4 \\times 4$ **unit lower-triangular** matrix, $L_3$ that eliminates all of the subdiagonal entries of the third column of $A^{(2)}$ yielding: \n",
    "\n",
    "$$\n",
    "\\begin{align}A^{(3)} &= L_{3}A^{(2)} \\\\ \n",
    "&= L_{3}L_{2}A^{(1)} \\\\\n",
    "&= L_{3}L_{2}L_{1}A \\\\\n",
    "&= U\n",
    "\\end{align}\n",
    "$$. \n",
    "\n",
    "Display the matrix $L_3$ using SymPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Type your answer here ##\n",
    "L3 = np.matrix([[1,,,],[,1,,],[,,1,],[,,,1]]) # for your convenience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ANSWER ##\n",
    "L3 = np.matrix([[1,0,0,0],[0,1,0,0],[0,0,1,0],[0,0,-1.25,1]])\n",
    "L3s = sym.Matrix(L3)\n",
    "L3s\n",
    "# L3s*A2s\n",
    "## ANSWER ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; <font color=red>**DO THIS:**</font> Left-multiply $A^{(2)}$ by $L_3$ to confirm that all of the subdiagonal entries of column 3 of $A^{(3)}$ are zero. Display the result via SymPy. **Note**: Your $u_{ij}$ will be whole, or Integer ($\\mathbb{Z}$), numbers. You should now notice that $A^{(3)} = U$ is in **row echelon form**, and, hence, $U$ is an **upper-triangular matrix** with $0$s below the diagonal!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Type your answer here ##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ANSWER ##\n",
    "A3 = L3*A2\n",
    "A3s = sym.Matrix(A3)\n",
    "A3s\n",
    "# sym.latex(A2s)\n",
    "## ANSWER ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sym.Matrix(L3*L2*L1*A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L3*L2*L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sym.Matrix(np.linalg.inv(L3*L2*L1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Congratulations! \n",
    "\n",
    "You have just decomposed your first matrix via the process below (and should now have a matrix, $U$, that looks like the one below):\n",
    "\n",
    "$$\n",
    "\\begin{align}L^{-1}A &= L_{3}L_{2}L_{1}A \\\\\n",
    "&= L_{3}L_{2}A^{(1)} \\\\\n",
    "&= L_{3}A^{(2)} \\\\\n",
    "&= A^{(3)} \\\\\n",
    "&= U \\\\\n",
    "&=\n",
    "\\begin{bmatrix}\n",
    "    2 & 1 & 1 & 0 \\\\\n",
    "    0 & 1 & 0 & 1 \\\\\n",
    "    0 & 0 & 4 & 2 \\\\\n",
    "    0 & 0 & 0 & 1.5\n",
    "\\end{bmatrix}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; <font color=red>**DO THIS:**</font>\n",
    "\n",
    "Finally, let's explicitly generate the matrices $L^{-1}$ and $L$. Then, display them using SymPy.\n",
    "\n",
    "It will be helpful to use the following:\n",
    "\n",
    "$$\\begin{align}L^{-1} &= L_{n-1}L_{n-2}...L_{2}L_{1}\\end{align}$$\n",
    "and\n",
    "$$\\begin{align}L &= (L^{-1})^{-1} \\\\\n",
    "&= (L_{n-1}L_{n-2}...L_{2}L_{1})^{-1} \\\\\n",
    "&= L_{1}^{-1}L_{2}^{-1}...L_{n-2}^{-1}L_{n-1}^{-1}\n",
    "\\end{align}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Type your answer here ##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sym.Matrix(L3*L2*L1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ANSWER ##\n",
    "L = np.linalg.inv(L1)*np.linalg.inv(L2)*np.linalg.inv(L3)\n",
    "Ls = sym.Matrix(L)\n",
    "\n",
    "\n",
    "Linv = L3*L2*L1\n",
    "Linvs = sym.Matrix(Linv)\n",
    "# Ls\n",
    "Linvs\n",
    "# sym.latex(A2s)\n",
    "## ANSWER ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sym.Matrix(L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our last bit of LU Decomposition fun, let's confirm that your matrices $L$ and $U$ fulfill the equality:\n",
    "\n",
    "$$A = LU$$\n",
    "\n",
    "Indeed, there is a function in SymPy that will compute the LU decomposition for us.\n",
    "\n",
    "&#9989; <font color=red>**DO THIS:**</font> Run the following function and print its outputs: \n",
    "\n",
    "$$\\texttt{L_actual, U_actual, _ = As.LUdecomposition()}$$\n",
    "\n",
    "Then, compute:\n",
    "\n",
    "$$\\texttt{L_actual*U_actual - As}$$\n",
    "\n",
    "and confirm that it outputs the zero matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Type your answer here ##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ANSWER ##\n",
    "L_actual, U_actual, _ = As.LUdecomposition()\n",
    "L_actual*U_actual - As\n",
    "## ANSWER ##\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# Part 2: Numerical Solution to the Heat Equation (PDE)\n",
    "\n",
    "Let us return to the Heat Equation presented in Part 0.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Symmetric Matrices\n",
    "\n",
    "From discretization of partial differential equations (PDEs) to matrix representations of networks to covariance matrices in statistics, symmetric matrices often arise through applications of Linear Algebra. A ***symmetric matrix*** is a matrix, $A$, for which $A = A^T$ (i.e., for every entry $(A)_{ij}$ {also written $a_{ij}$} of $A$ we have that $(A)_{ij} = (A)_{ji}$). An immediate consequence of this is that $A$ must be square. \n",
    "\n",
    "Symmetric matrices for which $x^TAx > 0$ for all nonzero $x\\in \\mathbb{R}^n$ are called ***positive-definite (PD)***. \n",
    "Symmetric positive-definite matrices are desirable from a computational standpoint, as they admit efficient solutions to $Ax=b$ via the Cholesky decomposition. \n",
    "Cholesky decomposition is very closely related to the LU decomposition, so we will build an algorithm to generate $LU$ from a matrix $A$ and then use the decomposition to numerically solve the heat equation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General LU Decomposition Algorithm \n",
    "\n",
    "&#9989; <font color=red>**DO THIS:**</font>  Using the scaffolded code below, complete the LU decomposition algorithm. (It may be helpful to test your code on the matrix $A$ from above.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Type your answer here ##\n",
    "## You just NEED to fill in the missing places in the codes ##\n",
    "A = np.matrix([[2,1,1,0],[4,3,3,1],[8,7,9,5],[6,7,9,8]]) # to test\n",
    "\n",
    "def LU_decomp(B):\n",
    "    n = len(B)\n",
    "    U = B.copy()\n",
    "    L = np.identity(n)\n",
    "    for k in np.arange(0,n-1):\n",
    "        for j in np.arange(k+1,n):\n",
    "            L[j,k] =\n",
    "            U[j,k:n] = U[,:] - L[,]*U[,:]\n",
    "    return L, U\n",
    "\n",
    "L1,U1 = LU_dec(A) # syntax for returning matrices\n",
    "np.linalg.norm(L1*U1 - A) # Test: should return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ANSWER ##\n",
    "B = np.matrix([[2,1,1,0],[4,3,3,1],[8,7,9,5],[6,7,9,8]]) # to test\n",
    "\n",
    "def LU_decomp(A):\n",
    "    n = len(A)\n",
    "    U = A.copy()\n",
    "    L = np.identity(n)\n",
    "    for k in np.arange(0,n-1):\n",
    "        for j in np.arange(k+1,n):\n",
    "            L[j,k] = U[j,k]/U[k,k]\n",
    "            U[j,k:n] = U[j,k:n] - L[j,k]*U[k,k:n]\n",
    "            \n",
    "    return L, U\n",
    "\n",
    "L2,U2 = LU_decomp(B)\n",
    "# L2\n",
    "np.linalg.norm(L2*U2 - B) # Test: should return 0\n",
    "## ANSWER ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solve $Ax=b$ via LU Decomposition\n",
    "\n",
    "You may wish to refer to the introduction of this assignment for a general overview of how to use LU decomposition to solve $Ax = b$.\n",
    "\n",
    "&#9989; <font color=red>**DO THIS:**</font>  Using the scaffolded code below, complete the LU solver algorithm. \n",
    "The algorithm should solve $Ly = b$ for $y$ via Forward-Substitution and then $Ux=y$ for $x$ by Backward-Substitution. \n",
    "(It may be helpful to test your code on a matrix $A$ and vector $b$ from homework 1 or another source.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Type your answer here ##\n",
    "## You just NEED to fill in the missing places in the codes ##\n",
    "def LU_Axb_solve(A,b):\n",
    "    L,U = LU_decomp(A)\n",
    "    n = len(A)\n",
    "    # Forward-Substitution: Ly = b for y\n",
    "    y = np.zeros((,))\n",
    "    for i in np.arange(0,n):\n",
    "        y[i] = b[i].copy()\n",
    "        for j in np.arange(0,i):\n",
    "            y[] = y[] - L[,]*y[]\n",
    "       \n",
    "    # Backward-Substitution: Ux = y for x\n",
    "    x = np.zeros((n,1))\n",
    "    for i in np.arange(n-1,-1,-1):\n",
    "        x[] = y[].copy()\n",
    "        for j in np.arange(n-1,i,-1):\n",
    "            x[] = x[] - U[,]*x[]\n",
    "        x[] = x[]/U[,]\n",
    "    \n",
    "    return np.mat(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ANSWER ##\n",
    "def LU_Axb_solve(A,b):\n",
    "    L,U = LU_decomp(A)\n",
    "    n = len(A)\n",
    "    # Forward-Substitution: Ly = b for y\n",
    "    y = np.zeros((n,1))\n",
    "    for i in np.arange(0,n):\n",
    "        y[i] = b[i].copy()\n",
    "        for j in np.arange(0,i):\n",
    "            y[i] = y[i] - L[i,j]*y[j]\n",
    "       \n",
    "    # Backward-Substitution: Ux = y for x\n",
    "    x = np.zeros((n,1))\n",
    "    for i in np.arange(n-1,-1,-1):\n",
    "        x[i] = y[i].copy()\n",
    "        for j in np.arange(n-1,i,-1):\n",
    "            x[i] = x[i] - U[i,j]*x[j]\n",
    "        x[i] = x[i]/U[i,i]\n",
    "    \n",
    "    return np.mat(x)\n",
    "## ANSWER ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's now -- finally -- solve the heat equation!\n",
    "\n",
    "Run the code below and enjoy the show you created! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of internal points\n",
    "N = 50 # Jupyter Hub requires N < 65 for this problem\n",
    " \n",
    "# Calculate Spatial Step-Size\n",
    "h = 1/(N+1.0)\n",
    " \n",
    "# Create Temporal Step-Size, TFinal, Number of Time-Steps\n",
    "k = h/2\n",
    "TFinal = 1\n",
    "NumOfTimeSteps = int(TFinal/k)\n",
    " \n",
    "# Create grid-points on x axis\n",
    "x = np.linspace(0,TFinal,N+2)\n",
    "x = x[1:-1]\n",
    " \n",
    "# Initial Conditions\n",
    "u = np.transpose(np.mat(100*np.sin(np.pi*x)))\n",
    "\n",
    "# Calculate Second-Derivative Matrix\n",
    "data = np.ones((3, N))\n",
    "data[1] = -2*data[1]\n",
    "diags = [-1,0,1]\n",
    "D2 = sparse.spdiags(data,diags,N,N)/(h**2)\n",
    "D = D2.todense()\n",
    "\n",
    "# Identity Matrix, A Matrix, b1 Matrix\n",
    "I = np.identity(N)\n",
    "A = (I -k/2*D)\n",
    "b1 = (I + k/2*D) \n",
    "\n",
    "# Data for each time-step\n",
    "data = []\n",
    " \n",
    "for i in range(NumOfTimeSteps):\n",
    "    # Solve the System: Au = b\n",
    "    b = b1*u\n",
    "    u = np.mat(LU_Axb_solve(A,b))\n",
    " \n",
    "    # Save Data\n",
    "    data.append(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Animate\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.set_xlim((0, TFinal))\n",
    "ax.set_ylim((1.02*np.min(data), 1.02*np.max(data)))\n",
    "plt.xlabel(\"meters along metal rod\")\n",
    "plt.ylabel(\"temperature\")\n",
    "\n",
    "line, = ax.plot([], [], lw=0.5, c='C1',marker='o')\n",
    "plt.close(fig)\n",
    "\n",
    "def init():\n",
    "    line.set_data([], [])\n",
    "    return (line,)\n",
    "\n",
    "def animate(t):\n",
    "    y = data[t]\n",
    "    line.set_data(x, y)\n",
    "    return (line,)\n",
    "\n",
    "anim = animation.FuncAnimation(fig, animate, init_func=init,\n",
    "                               frames=100, interval=20, \n",
    "                               blit=True)\n",
    "\n",
    "HTML(anim.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; <font color=red>**DO THIS:**</font>  Before turning in your notebook, verify you have answered all the questions.  \n",
    "- Use the Red/Bold (<font color=red>**QUESTION**</font> and <font color=red>**DO THIS**</font> )  text as a guild to where you will be evaluated. \n",
    "- The check mark symbols (&#9989;) are provided to help you keep track of what you have completed. Feel free to remove the check mark after completing each item. \n",
    "- Before submitting your document, Clear and Restart the Kernel and Rerun the entire notebook. **THERE SHOULD BE NO ERRORS**\n",
    "\n",
    "\n",
    "\n",
    "---------\n",
    "### Congratulations, you're done with your Homework assignment!\n",
    "\n",
    "\n",
    "Now, you just need to submit this assignment by uploading it to the course <a href=\"https://d2l.msu.edu/\">Desire2Learn</a> web page for today's dropbox (Don't forget to add your names in the first cell)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#169; Copyright 2018,  Michigan State University Board of Trustees"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
